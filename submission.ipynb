{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "import sys \n",
    "sys.path.append('.')\n",
    "\n",
    "\n",
    "from cgiar.utils import get_dir\n",
    "from cgiar.model import ResNetMultipleMLP, XCITMultipleMLP\n",
    "from cgiar.data import CGIARDataset_V4, augmentations\n",
    "\n",
    "# reduce font size of plots\n",
    "plt.rcParams.update({'font.size': 8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED=42\n",
    "LR=1e-4\n",
    "EPOCHS=35\n",
    "IMAGE_SIZE=224\n",
    "INITIAL_SIZE=512\n",
    "TRAIN_BATCH_SIZE=128\n",
    "TEST_BATCH_SIZE=256\n",
    "HIDDEN_SIZE=128\n",
    "NUM_FOLDS=5\n",
    "NUM_VIEWS=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure reproducibility\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = get_dir('data/')\n",
    "ARTIFACTS = get_dir('solutions/v10/#3/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(IMAGE_SIZE),\n",
    "    augmentations[\"RandomEqualize\"],\n",
    "    augmentations[\"RandomAffine\"],\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8663 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8663/8663 [03:02<00:00, 47.54it/s] \n"
     ]
    }
   ],
   "source": [
    "# Load test data frame from csv\n",
    "X_test = pd.read_csv(DATA_DIR / 'Test.csv')\n",
    "\n",
    "test_images = CGIARDataset_V4.load_images(X_test, DATA_DIR / \"test\", INITIAL_SIZE)\n",
    "test_images = dict([test_images[idx] for idx in range(len(test_images))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct test dataset and dataloader\n",
    "test_dataset = CGIARDataset_V4(\n",
    "    images=test_images,\n",
    "    num_views=NUM_VIEWS,\n",
    "    transform=transform,\n",
    "    features=X_test,\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=TEST_BATCH_SIZE, \n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    0: 1.0,\n",
    "    # 2: 1.0,\n",
    "    # 3: 1.0,\n",
    "    # 4: 1.0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models(device):\n",
    "    \n",
    "    models = {}\n",
    "    \n",
    "    for i in weights.keys():\n",
    "        # initialize the model\n",
    "        model = XCITMultipleMLP(\n",
    "            model_name=\"xcit_nano_12_p16_224\",\n",
    "            pretrained=True,\n",
    "            num_mlps=4,\n",
    "            hidden_size=HIDDEN_SIZE\n",
    "        )\n",
    "        \n",
    "        # load the model weights\n",
    "        model.load_state_dict(torch.load(ARTIFACTS / f\"model_fold_{i}.pth\", map_location=device))\n",
    "        \n",
    "        # move model to gpu\n",
    "        model = model.to(device)\n",
    "        \n",
    "        # set model to evaluation mode\n",
    "        model.eval()\n",
    "        \n",
    "        models[i] = model\n",
    "        \n",
    "        # activate all dropout layers\n",
    "        # for module in model.modules():\n",
    "        #     if isinstance(module, torch.nn.Dropout):\n",
    "        #         module.train()\n",
    "        \n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [07:38<00:00, 13.49s/it]\n"
     ]
    }
   ],
   "source": [
    "test_ensemble_predictions = []\n",
    "\n",
    "\n",
    "with torch.cuda.device(0):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    models = get_models(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for ids, images_list, growth_stage, season, _ in tqdm(test_loader):\n",
    "            \n",
    "            outputs = torch.zeros(len(ids)).to(device)\n",
    "            \n",
    "            for idx in weights.keys():\n",
    "            \n",
    "                # average predictions from all the views\n",
    "                outputs += weights[idx] * torch.stack([models[idx]((\n",
    "                    growth_stage.to(device).squeeze(),\n",
    "                    season.to(device).squeeze(),\n",
    "                    images.to(device)\n",
    "                )) for images in images_list]).mean(dim=0)\n",
    "            \n",
    "            # get predictions from all the folds\n",
    "            outputs = outputs.tolist()\n",
    "            test_ensemble_predictions.extend(list(zip(ids, outputs)))\n",
    "\n",
    "# load the sample submission file and update the extent column with the predictions\n",
    "submission_df = pd.read_csv('data/SampleSubmission.csv')\n",
    "\n",
    "# update the extent column with the predictions\n",
    "submission_df['extent'] = submission_df['ID'].map(dict(test_ensemble_predictions))\n",
    "\n",
    "# save the submission file and trained model\n",
    "submission_df.to_csv('submission_ensemble.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Predictions (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/26068 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26068/26068 [09:13<00:00, 47.07it/s] \n"
     ]
    }
   ],
   "source": [
    "# Load test data frame from csv\n",
    "df_train = pd.read_csv(DATA_DIR / 'Train.csv')\n",
    "X_train = df_train.drop(columns=['extent'], axis=1)\n",
    "y_train = df_train['extent']\n",
    "\n",
    "train_images = CGIARDataset_V4.load_images(X_train, DATA_DIR / \"train\", INITIAL_SIZE)\n",
    "train_images = dict([train_images[idx] for idx in range(len(train_images))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct test dataset and dataloader\n",
    "train_dataset = CGIARDataset_V4(\n",
    "    transform=transform,\n",
    "    labels=y_train,\n",
    "    features=X_train,\n",
    "    images=train_images,\n",
    "    num_views=NUM_VIEWS,\n",
    ")\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=TEST_BATCH_SIZE, \n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [13:27<00:00,  7.91s/it]\n"
     ]
    }
   ],
   "source": [
    "train_ensemble_predictions = []\n",
    "\n",
    "\n",
    "with torch.cuda.device(1):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    models = get_models(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for ids, images_list, growth_stage, season, _ in tqdm(train_loader):\n",
    "            \n",
    "            outputs = torch.zeros(len(ids)).to(device)\n",
    "            \n",
    "            for idx in weights.keys():\n",
    "            \n",
    "                # average predictions from all the views\n",
    "                outputs += weights[idx] * torch.stack([models[idx]((\n",
    "                    growth_stage.to(device).squeeze(),\n",
    "                    season.to(device).squeeze(),\n",
    "                    images.to(device)\n",
    "                )) for images in images_list]).mean(dim=0)\n",
    "            \n",
    "            # get predictions from all the folds\n",
    "            outputs = outputs.tolist()\n",
    "            train_ensemble_predictions.extend(list(zip(ids, outputs)))\n",
    "\n",
    "# update the extent column with the predictions\n",
    "df_train['predicted_extent'] = df_train['ID'].map(dict(train_ensemble_predictions))\n",
    "\n",
    "# save the submission file and trained model\n",
    "df_train.to_csv('train_predictions_ensemble.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cgiar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
